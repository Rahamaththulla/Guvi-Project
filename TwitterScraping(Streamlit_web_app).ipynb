{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMMEocRR5R5w7KrUuki5qE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahamaththulla/Guvi-Project/blob/main/TwitterScraping(Streamlit_web_app).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZWCKh9Zb0ov"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlitapp.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from datetime import date\n",
        "import pymongo\n",
        "import json\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "from PIL import Image\n",
        "st.title(\"Twitter Scraping\")\n",
        "today=str(date.today())\n",
        "def Scrapingdata(Hashtag,start_date,End_date,tweets_count):\n",
        "      tweets_list=[]\n",
        "      for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{Hashtag} since:{start_date} until:{End_date}').get_items()):\n",
        "           if i>=tweets_count:\n",
        "               break\n",
        "           tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.url, tweet.retweetCount, tweet.source, tweet.likeCount,tweet.replyCount,tweet.lang])\n",
        "      return(tweets_list)\n",
        "menu=[\"Home\",\"About\",\"Search\",\"Display\",\"Download\"]\n",
        "choice=st.sidebar.selectbox(\"menu\",menu)\n",
        "if choice==\"Home\": \n",
        "    st.markdown(\"_This app is a Twitter Scraping web app created using streamlit. It scrapes the twitter data for the given hashtag/keyword for the given period. The tweets are uploaded in Mongodb and can be download as csv or json file._\")\n",
        "    img=Image.open(\"/content/ElonMusk.webp\")\n",
        "    st.image(img)\n",
        "elif choice==\"About\":\n",
        "    with st.expander(\"Twitter Scraping\"):\n",
        "        st.write(\"Twitter Scraper will scrap the data from Public Twitter Profiles.It will collect the data about***date,id,url,tweet content,reply count,retweet,count,language,like count,followers and lot more information***t to gather the real facts about the Tweets\")\n",
        "    with st.expander(\"Snscrape\"):\n",
        "        st.write(\"Snscrape is a scraper for social media services like ** twitter, facebook, instagram** and so on. It scrapes **user profiles, hashtages, other tweet information** and returns the discovered items\")\n",
        "    with st.expander(\"Mongodb\"):\n",
        "        st.write(\"mongodb is an open source document database used for storing unstructured data. It is used by developers to work easily with real time data analysis,content management and lot of other web applications\")\n",
        "    with st.expander(\"Streamlit\"):\n",
        "        st.write(\"Streamlit is a awesome opensource framwork used for building highly interactive sharable web applications in python language. Its easy to share machine learning and datascience web apps using streamlit. It allows the app to load the large set of dates from web for manipulation and performing expensive computations.\")\n",
        "elif choice==\"Search\":\n",
        "    Hashtag=st.text_input(\"Enter Hashtag or Keyword\")\n",
        "    start_date=st.date_input(\"Enter starting date:(YYYY-MM-DD)\")\n",
        "    End_date=st.date_input(\"Enter end date:(YYYY-MM-DD)\")\n",
        "    tweets_count=st.number_input(\"Enter Tweet count\",min_value=1,max_value=1500,step=2)\n",
        "    if Hashtag:\n",
        "        submit=st.checkbox(\"***Scraped TWeet***\")\n",
        "        if submit:\n",
        "\n",
        "             data=Scrapingdata(Hashtag,start_date,End_date,tweets_count)\n",
        "             st.success(\"Data scraped successfully\")\n",
        "             def data_frame(data):\n",
        "                    return pd.DataFrame(data,columns=['Datetime', 'Tweet Id', 'Text', 'Username',\"url\",\"retweetCount\",\"source\",\"like_count\",\"replycount\",\"lan\"])\n",
        "             df=data_frame(data)\n",
        "             client = pymongo.MongoClient(\"mongodb+srv://rahamaththullah:Rilvan1234@cluster0.wxicfev.mongodb.net/?retryWrites=true&w=majority\")\n",
        "             db = client.Twitter\n",
        "             records=db.scrapping\n",
        "             scr_data={\"Scraped_word\":Hashtag,\"Scraped_date\":today,\"Scraped_data\":df.to_dict(\"list\")}\n",
        "             records.delete_many({})\n",
        "             records.insert_one(scr_data)\n",
        "             st.success(\"upload to mongodb Successful\")\n",
        "             \n",
        "\n",
        "    else:\n",
        "         st.checkbox(\"scrapedtweet\",disabled=True)\n",
        "elif choice==\"Display\":\n",
        "    Hashtag=st.sidebar.text_input(\"Enter Hashtag or Keyword\")\n",
        "    start_date=st.sidebar.date_input(\"Enter starting date:(YYYY-MM-DD)\")\n",
        "    End_date=st.sidebar.date_input(\"Enter end date:(YYYY-MM-DD)\")\n",
        "    tweets_count=st.sidebar.number_input(\"Enter Tweet count\",min_value=1,max_value=1500,step=2)\n",
        "    list_tweet=Scrapingdata(Hashtag,start_date,End_date,tweets_count)\n",
        "    def data_frame(data):\n",
        "         return(pd.DataFrame(data,columns=['Datetime', 'Tweet Id', 'Text', 'Username',\"url\",\"retweetCount\",\"source\",\"like_count\",\"replycount\",\"lan\"]))\n",
        "    df=data_frame(list_tweet)\n",
        "    submit=st.checkbox(\"View Dataframe\") \n",
        "    if submit:\n",
        "          st.success(\"Dataframe\")\n",
        "          st.write(df) \n",
        "elif choice==\"Download\":\n",
        "    Hashtag=st.sidebar.text_input(\"Enter Hashtag or Keyword\")\n",
        "    start_date=st.sidebar.date_input(\"Enter starting date:(YYYY-MM-DD)\")\n",
        "    End_date=st.sidebar.date_input(\"Enter end date:(YYYY-MM-DD)\")\n",
        "    tweets_count=st.sidebar.number_input(\"Enter Tweet count\",min_value=1,max_value=1500,step=2)\n",
        "    tweetlist=Scrapingdata(Hashtag,start_date,End_date,tweets_count)\n",
        "    def data_frame(data):\n",
        "         return(pd.DataFrame(data,columns=['Datetime', 'Tweet Id', 'Text', 'Username',\"url\",\"retweetCount\",\"source\",\"like_count\",\"replycount\",\"lan\"]))\n",
        "    \n",
        "    def convert_csv(df_input_csv):\n",
        "          return df_input_csv.to_csv().encode(\"utf-8\")\n",
        "\n",
        "    def convert_json(j):\n",
        "          return j.to_json(orient=\"index\")\n",
        "\n",
        "    df=data_frame(tweetlist)\n",
        "    csv=convert_csv(df)\n",
        "    json = convert_json(df)\n",
        "    st.download_button(label=\"Download csv\",data=csv,file_name=\"file.csv\",mime=\"text/csv\") \n",
        "    st.download_button(label=\"Download json\",data=json,file_name=\"file.json\",mime=\"text/csv\")"
      ]
    }
  ]
}